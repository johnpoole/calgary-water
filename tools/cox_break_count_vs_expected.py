"""Compare observed break counts vs Cox model output.

Creates a per-main table with:
- observed_breaks: count of matched break events per pipe (based on break→main link table)
- expected_breaks: expected count proportional to Cox hazard_score (scaled to total observed)
- diff_breaks: observed_breaks - expected_breaks

Inputs:
- outputs/breaks/breaks_to_mains_largest_within_3m.csv (generated by tools/link_breaks_to_mains.py)
- outputs/cox/segment_hazard_scores.csv (generated by tools/cox_ph_model.py)

Output:
- outputs/cox/break_count_vs_expected.csv

Notes:
- This is a simple proportional scaling of hazard scores to counts; it is not a calibrated
  probabilistic model.
"""

from __future__ import annotations

import csv
from pathlib import Path
from typing import Dict, Tuple

import pandas as pd

REPO_ROOT = Path(__file__).resolve().parents[1]
LINKS_CSV = REPO_ROOT / "outputs" / "breaks" / "breaks_to_mains_largest_within_3m.csv"
COX_CSV = REPO_ROOT / "outputs" / "cox" / "segment_hazard_scores.csv"
OUT_CSV = REPO_ROOT / "outputs" / "cox" / "break_count_vs_expected.csv"


def load_observed_counts() -> Tuple[Dict[str, int], int]:
    if not LINKS_CSV.exists():
        raise SystemExit(
            f"Missing break→main links: {LINKS_CSV}\n"
            "Generate with: python tools/link_breaks_to_mains.py --mode largest --within-m 3"
        )

    df = pd.read_csv(LINKS_CSV)
    if "main_globalid" not in df.columns:
        raise SystemExit(f"Unexpected links schema (missing main_globalid): {LINKS_CSV}")

    df["main_globalid"] = df["main_globalid"].astype(str).str.strip()
    df = df[df["main_globalid"].astype(bool)]

    counts = df.groupby("main_globalid").size().astype(int).to_dict()
    total = int(df.shape[0])
    return counts, total


def load_hazard_scores() -> Dict[str, float]:
    if not COX_CSV.exists():
        raise SystemExit(
            f"Missing Cox scores: {COX_CSV}\n"
            "Generate with: python tools/cox_ph_model.py"
        )

    df = pd.read_csv(COX_CSV, usecols=["id", "hazard_score"])
    df["id"] = df["id"].astype(str).str.strip().str.lower()
    df["hazard_score"] = pd.to_numeric(df["hazard_score"], errors="coerce")
    df = df[df["id"].astype(bool)]
    df = df[df["hazard_score"].notna()]

    return dict(zip(df["id"].tolist(), df["hazard_score"].astype(float).tolist()))


def main() -> None:
    observed_by_gid, total_observed = load_observed_counts()
    hazard_by_id_lower = load_hazard_scores()

    # Scale expected breaks so total expected equals total observed, but ONLY over pipes
    # that are present in the Cox output (hazard scores available).
    hazard_sum_included = 0.0
    observed_included = 0
    observed_missing_hazard = 0

    for gid, observed in observed_by_gid.items():
        hazard = float(hazard_by_id_lower.get(str(gid).strip().lower(), 0.0))
        if hazard > 0:
            hazard_sum_included += hazard
            observed_included += int(observed)
        else:
            observed_missing_hazard += int(observed)

    if hazard_sum_included <= 0:
        raise SystemExit("No observed-break pipes have Cox hazard scores; cannot scale expected counts.")

    rows = []
    expected_total = 0.0

    for gid, observed in observed_by_gid.items():
        hid = str(gid).strip().lower()
        hazard = float(hazard_by_id_lower.get(hid, 0.0))

        expected = None
        diff = None
        if hazard > 0:
            expected = (hazard / hazard_sum_included) * float(observed_included)
            expected_total += float(expected)
            diff = float(observed) - float(expected)

        rows.append(
            {
                "id": str(gid),
                "observed_breaks": int(observed),
                "expected_breaks": (float(expected) if expected is not None else ""),
                "diff_breaks": (float(diff) if diff is not None else ""),
                "hazard_score": float(hazard),
            }
        )

    def _sort_key(r):
        try:
            return float(r.get("diff_breaks") or float("-inf"))
        except Exception:
            return float("-inf")

    rows.sort(key=_sort_key, reverse=True)

    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)
    with OUT_CSV.open("w", encoding="utf-8", newline="") as f:
        w = csv.DictWriter(
            f,
            fieldnames=["id", "observed_breaks", "expected_breaks", "diff_breaks", "hazard_score"],
        )
        w.writeheader()
        w.writerows(rows)

    print(f"Wrote {OUT_CSV}")
    print(
        "Summary",
        {
            "pipes_with_observed_breaks": len(observed_by_gid),
            "total_observed_breaks": int(total_observed),
            "observed_breaks_included_in_cox": int(observed_included),
            "observed_breaks_missing_cox": int(observed_missing_hazard),
            "expected_total_included": float(expected_total),
        },
    )


if __name__ == "__main__":
    main()
